<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Kafka入门+实战]]></title>
    <url>%2F2019%2F11%2F30%2FKafka%E5%85%A5%E9%97%A8%2B%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[Kafka入门+实战第 1 章 Kafka概述1.1 定义Kafka 是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。 1.2 消息队列1.2.1 传统消息队列的应用场景MQ传统应用场景之异步处理： 使用消息队列的好处 解耦允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。 可恢复性系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。 缓冲有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况（生产消息的速度 &gt; 消费消息的速度）。 灵活性 &amp; 峰值处理能力 （削峰）在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。 异步通信很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。 1.2.2 消息队列的两种模式 点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除）消息生产者生产消息发送到Queue中，然后消息消费者从Queue中取出并且消费消息。 消息被消费以后，Queue 中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue 支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。 发布/订阅模式（一对多，消费者消费数据之后不会清除消息） 消息生产者（发布）将消息发布到 topic 中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到 topic 的消息会被所有订阅者消费。其中，发布/订阅模式又分为两种： 一种为消费者主动拉取队列中数据(Kafka就属于这种模式)。这种模式有一个缺点就是要维护一个长轮询，不断去拉取数据，造成资源浪费。 一种为由队列主动推送给消费者。 图为发布订阅模式： 1.3 Kafka 基础架构Kafka架构图： Producer ：消息生产者，就是向 kafka broker 发消息的客户端； Consumer ：消息消费者，向 kafka broker 取消息的客户端； Consumer Group （CG）：消费者组，由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。 如果分区数大于或者等于组中的消费者实例数，一个消费者会负责多个分区。当然最理想的是分区数等于组中的消费者实例数。 Broker ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker可以容纳多个 topic。 Topic ：可以理解为一个队列，生产者和消费者面向的都是一个 topic Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列； Replica：副本，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且 kafka 仍然能够继续工作，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 leader 和若干个 follower。 leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是 leader。 follower：每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和 leader 数据的同步。leader 发生故障时，某个 follower 会成为新的 follower。 第 2 章 Kafka 快速入门2.1 安装部署2.1.1 集群规划linux1 linux2 linux3 zk zk zk kafka kafka kafka 2.1.2 安装包下载下载地址 这里使用0.11.0.0版本 2.1.3 集群部署 下面流程中，只有配置文件中的broker.id不同，其他在各个机器上都是相同的操作 1、解压安装包：把下载的安装包放到/opt/software下并解压 1[kaizhang@localhost software]$ tar -zxvf kafka_2.11-0.11.0.0.gz 2、修改解压后的文件名 1[kaizhang@localhost software]$ mv kafka_2.11-0.11.0.0 kafka 3、在/opt/software/kafka 目录下创建 logs 文件夹 1[kaizhang@localhost kafka_2.11-0.11.0.0]$ mkdir logs 4、修改配置文件 12[kaizhang@localhost kafka_2.11-0.11.0.0]$ cd config[kaizhang@localhost config]$ vi server.properties ​ 修改部分配置如下：(其中三台centos中broker.id分别是1、2、3，不得重复) 123456789101112131415161718192021222324252627#broker的全局唯一编号，不能重复broker.id=1 #删除topic功能使能delete.topic.enable=true #kafka服务器需要监听的端口号。如果是在本机上跑虚拟机运行可以不用配置本项，默认会使用localhost的地址，如果是在远程服务器上运行则必须配置#例如：listeners=PLAINTEXT:// 192.168.1.1:9092。并确保服务器的9092端口能够访问#listeners=PLAINTEXT://:9092#处理网络请求的线程数量num.network.threads=3 #用来处理磁盘IO的现成数量num.io.threads=8 #发送套接字的缓冲区大小socket.send.buffer.bytes=102400 #接收套接字的缓冲区大小socket.receive.buffer.bytes=102400 #请求套接字的缓冲区大小socket.request.max.bytes=104857600 #kafka运行日志存放的路径log.dirs=/opt/software/kafka/logs #topic在当前broker上的分区个数num.partitions=1 #用来恢复和清理data下数据的线程数量num.recovery.threads.per.data.dir=1 #segment文件保留的最长时间，超时将被删除log.retention.hours=168 #配置连接Zookeeper集群地址zookeeper.connect=192.168.17.101:2181,192.168.17.102:2181,192.168.17.103:2181 5、配置环境变量 1234567kaizhang@localhost config]$ sudo vi /etc/profile #KAFKA_HOMEexport KAFKA_HOME=/opt/software/kafkaexport PATH=$PATH:$KAFKA_HOME/bin [kaizhang@localhost config]$ source /etc/profile 6、启动集群 ​ 依次在三台机器上启动kafka 1[kaizhang@server1 kafka]$ bin/kafka-server-start.sh -daemon config/server.properties [kaizhang@server2 kafka]$ bin/kafka-server-start.sh -daemon config/server.properties [kaizhang@server3 kafka]$ bin/kafka-server-start.sh -daemon config/server.properties 7、关闭集群 123[kaizhang@server1 kafka]$ bin/kafka-server-stop.sh[kaizhang@server2 kafka]$ bin/kafka-server-stop.sh[kaizhang@server3 kafka]$ bin/kafka-server-stop.sh 8、kafka操作脚本 123456789101112131415#!/bin/bashcase $1 in"start")&#123; echo "========== server1 start ==========" sh /opt/software/kafka/bin/kafka-server-start.sh -daemon /opt/software/kafka/config/server.properties&#125;;case $1 in"stop")&#123; echo "========== server1 stop ===========" sh /opt/software/kafka/bin/kafka-server-stop.sh -daemon /opt/software/kafka/config/server.properties&#125;; esac 2.2 Kafka命令行操作(在/opt/software/kafka目录下执行命令)1、查看当前服务器中的所有 topic 1234[kaizhang@server1 kafka]$ bin/kafka-topics.sh --zookeeper server1:2181 --list__consumer_offsetsfivefour 2、创建 topic 12[kaizhang@server1 kafka]$ bin/kafka-topics.sh --zookeeper server1:2181 --create --replication-factor 2 --partitions 3 --topic firstCreated topic "first". 选项说明：–topic 定义 topic 名–replication-factor 定义副本数–partitions 定义分区数 在创建完topic后，可以到kafka数据文件中查看，这里到设置的目录里查看即 log.dirs=/opt/software/kafka/logs 12drwxrwxr-x. 2 kaizhang kaizhang 141 12月 13 00:04 first-0drwxrwxr-x. 2 kaizhang kaizhang 141 12月 13 00:04 first-1 在first-0中，first是主题名称，0为分区 这里first主题是3个分区，2个副本，所以在三台服务器的日志文件中共可以看到6个first相关的数据： first-0、first-1、first-2、first-0、first-1、first-2 如果创建的是2个分区，3个副本，则数据为： first-0、first-0、first-0、first-1、first-1、first-1 1234[kaizhang@server1 kafka]$ bin/kafka-topics.sh --zookeeper server1:2181 --create --replication-factor 4 --partitions 2 --topic firstError while executing topic command : replication factor: 4 larger than available brokers: 3[2019-12-13 00:22:07,440] ERROR org.apache.kafka.common.errors.InvalidReplicationFactorException: replication factor: 4 larger than available brokers: 3 (kafka.admin.TopicCommand$) 12[2019-12-13 00:23:10,391] ERROR org.apache.kafka.common.errors.InvalidReplicationFactorException: replication factor must be larger than 0 (kafka.admin.TopicCommand$) 这里可以看到，如果副本数等于0或者大于服务器个数，都是会报错的 3、删除topic 123[kaizhang@server1 kafka]$ bin/kafka-topics.sh --zookeeper server1:2181 --delete --topic firstTopic first is marked for deletion.Note: This will have no impact if delete.topic.enable is not set to true. 需要 server.properties 中设置 delete.topic.enable=true 否则只是标记删除。 4、发送消息 123[kaizhang@server1 kafka]$ bin/kafka-console-producer.sh --topic first --broker-list server1:9092&gt;hello world&gt;kafka 其中9092是kafka服务器需要监听的端口号，在server.properties文件中配置。 5、消费消息 123456#通过zookeeper消费，这是kafka 0.9版本之前的消费方式，0.9版本之前消息是存放在zookeeper中的[kaizhang@server3 kafka]$ bin/kafka-console-consumer.sh --zookeeper server1:2181 --topic first #通过kafka 0.9版本之后的消费方式[kaizhang@server3 kafka]$ bin/kafka-console-consumer.sh --bootstrap-server server1:9092 --topic first#从最初的的消息开始[kaizhang@server3 kafka]$ bin/kafka-console-consumer.sh --bootstrap-server server1:9092 --topic first --from-beginning –from-beginning：会把主题中以往所有的数据都读取出来。 6、查看某个 Topic 的详情 12345[kaizhang@server1 kafka]$ bin/kafka-topics.sh --zookeeper server1:2181 --describe --topic firstTopic:first PartitionCount:3 ReplicationFactor:2 Configs: Topic: first Partition: 0 Leader: 1 Replicas: 1,2 Isr: 1,2 Topic: first Partition: 1 Leader: 2 Replicas: 2,3 Isr: 2,3 Topic: first Partition: 2 Leader: 3 Replicas: 3,1 Isr: 3,1 7、修改分区数 123[kaizhang@server1 kafka]$ bin/kafka-topics.sh --zookeeper server1:2181 --alter --topic first --partitions 6 WARNING: If partitions are increased for a topic that has a key, the partition logic or ordering of the messages will be affectedAdding partitions succeeded! 12345678910111213[kaizhang@server1 kafka]$ bin/kafka-topics.sh --zookeeper server1:2181 --alter --topic first --partitions 2WARNING: If partitions are increased for a topic that has a key, the partition logic or ordering of the messages will be affectedError while executing topic command : The number of partitions for a topic can only be increased[2019-12-13 00:31:37,496] ERROR kafka.admin.AdminOperationException: The number of partitions for a topic can only be increased at kafka.admin.AdminUtils$.addPartitions(AdminUtils.scala:292) at kafka.admin.TopicCommand$$anonfun$alterTopic$1.apply(TopicCommand.scala:147) at kafka.admin.TopicCommand$$anonfun$alterTopic$1.apply(TopicCommand.scala:124) at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59) at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48) at kafka.admin.TopicCommand$.alterTopic(TopicCommand.scala:124) at kafka.admin.TopicCommand$.main(TopicCommand.scala:64) at kafka.admin.TopicCommand.main(TopicCommand.scala) (kafka.admin.TopicCommand$) 这里可以看到，分区数只能增加，不能减少]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper集群搭建及内部原理]]></title>
    <url>%2F2019%2F09%2F29%2FZookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E5%8F%8A%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[第1章 Zookeeper 实战1.1 分布式安装部署0）集群规划在CentOS_1、CentOS_2 和CentOS_3 三个服务器上部署 Zookeeper。 1）解压安装1、解压 zookeeper 安装包到/opt/software/目录下1[kaizhang@localhost software]$ tar -zxvf zookeeper-3.4.14.tar.gz 2、在/opt/software/zookeeper-3.4.14/这个目录下创建 zkData1[kaizhang@localhost zookeeper-3.4.14]$ mkdir -p zkData 3、复制/opt/software/zookeeper-3.4.14/conf 这个目录下的 zoo_sample.cfg 为 zoo.cfg1[kaizhang@localhost conf]$ cp zoo_sample.cfg zoo.cfg 2）配置 zoo.cfg 文件1、具体配置123456dataDir=/opt/software/zookeeper-3.4.14/zkData 增加如下配置 #######################cluster##########################server.1=192.168.17.101:2888:3888server.2=192.168.17.102:2888:3888server.3=192.168.17.103:2888:3888 2、配置参数解读1234567Server.A=B:C:D。 A 是一个数字，表示这个是第几号服务器； B 是这个服务器的 ip 地址； C 是这个服务器与集群中的 Leader 服务器交换信息的端口； D 是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。集群模式下配置一个文件myid，这个文件在dataDir目录下，这个文件里面有一个数据就是 A 的值，Zookeeper 启动时读取此文件，拿到里面的数据与 zoo.cfg 里面的配置信息比较从而判断到底是哪个 server。 3） 修改日志输出位置 当执行zkServer.sh 时，会在执行命令的文件夹下会产生zookeeper.out日志文件记录zookeeper的运行日志，该种方式会让日志文件不便于查找，容易遗忘。这里修改日志输出到指定文件夹。 1、修改bin/log4j.properties文件 zookeeper.out文件属于运行时的日志文件，通过conf/log4j.properties文件配置。 1234567# 以下是原配置zookeeper.root.logger=INFO, CONSOLElog4j.appender.ROLLINGFILE=org.apache.log4j.RollingFileAppender# 以下是修改后配置zookeeper.root.logger=INFO, ROLLINGFILElog4j.appender.ROLLINGFILE=org.apache.log4j.RollingFileAppender 2、在/opt/software/zookeeper-3.4.14下创建日志目录1[kaizhang@localhost zookeeper-3.4.14]$ mkdir logs 3、修改bin/zkEnv.sh12345678910111213141516171819202122# 以下是原配置if [ &quot;x$&#123;ZOO_LOG_DIR&#125;&quot; = &quot;x&quot; ]then ZOO_LOG_DIR=&quot;.&quot;fiif [ &quot;x$&#123;ZOO_LOG4J_PROP&#125;&quot; = &quot;x&quot; ]then ZOO_LOG4J_PROP=&quot;INFO,CONSOLE&quot;fi# 以下是修改后配置if [ &quot;x$&#123;ZOO_LOG_DIR&#125;&quot; = &quot;x&quot; ]then ZOO_LOG_DIR=&quot;/opt/software/zookeeper-3.4.14/logs&quot;fiif [ &quot;x$&#123;ZOO_LOG4J_PROP&#125;&quot; = &quot;x&quot; ]then ZOO_LOG4J_PROP=&quot;INFO,ROLLINGFILE&quot;fi 3）集群操作1、在/opt/software/zookeeper-3.4.14/zkData 目录下创建一个 myid 的文件1[kaizhang@localhost zkData]$ touch myid 添加 myid 文件，注意一定要在 linux 里面创建，在 notepad++里面很可能乱码 2、编辑 myid 文件1[kaizhang@localhost zkData]$ vi myid 在文件中添加与 server 对应的编号：如 1 3、在其他机器上进行相同的操作 ，并分别修改 myid 文件中内容为 2、34、在三台机器上分别启动 zookeeper1[kaizhang@localhost bin]$ ./zkServer.sh start 5、查看状态1234567891011121314[kaizhang@localhost bin]$ ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/software/zookeeper-3.4.14/bin/../conf/zoo.cfgMode: leader[kaizhang@localhost bin]$ ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/software/zookeeper-3.4.14/bin/../conf/zoo.cfgMode: follower[kaizhang@localhost bin]$ ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/software/zookeeper-3.4.14/bin/../conf/zoo.cfgMode: follower 6、操作脚本12345678910111213141516171819#!/bin/bashcase $1 in"start")&#123; echo "========== server2 start ==========" sh /opt/software/zookeeper-3.4.14/bin/zkServer.sh start&#125;;;"stop")&#123; echo "========== server2 stop ==========" sh /opt/software/zookeeper-3.4.14/bin/zkServer.sh stop&#125;;;"status")&#123; echo "========== server2 status ==========" sh /opt/software/zookeeper-3.4.14/bin/zkServer.sh status&#125;;;esac 1.2 客户端命令行操作 命令基本语法 功能描述 help 显示所有操作命令 ls path [watch] 使用 ls 命令来查看当前znode中所包含的内容 ls2 path [watch] 查看当前节点数据并能看到更新次数等数据 create 普通创建 -s 含有序列 -e 临时（重启或者超时消失） get path [watch] 获得节点的值 set 设置节点的具体值 stat 查看节点状态 delete 删除节点 rmr 递归删除节点 ​ 1）启动客户端 1[kaizhang@localhost bin]$ ./zkCli.sh ​ 2）显示所有操作命令 1[zk: localhost:2181(CONNECTED) 0] help ​ 3）查看当前 znode 中所包含的内容 12[zk: localhost:2181(CONNECTED) 1] ls /[zookeeper] ​ 4）查看当前节点数据并能看到更新次数等数据 12345678910111213[zk: localhost:2181(CONNECTED) 2] ls2 /[zookeeper]cZxid = 0x0ctime = Thu Jan 01 08:00:00 CST 1970mZxid = 0x0mtime = Thu Jan 01 08:00:00 CST 1970pZxid = 0x0cversion = -1dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 0numChildren = 1 ​ 5）创建普通节点 12345[zk: localhost:2181(CONNECTED) 3] create /app1 &quot;hello app1&quot; Created /app1[zk: localhost:2181(CONNECTED) 4] create /app1/server101 &quot;192.168.1.101&quot;Created /app1/server101 ​ 6）获得节点的值 123456789101112131415161718192021222324252627[zk: localhost:2181(CONNECTED) 5] get /app1hello app1cZxid = 0x100000004ctime = Mon Sep 30 21:27:00 CST 2019mZxid = 0x100000004mtime = Mon Sep 30 21:27:00 CST 2019pZxid = 0x100000007cversion = 1dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 10numChildren = 1[zk: localhost:2181(CONNECTED) 6] get /app1/server101192.168.1.101cZxid = 0x100000007ctime = Mon Sep 30 21:28:25 CST 2019mZxid = 0x100000007mtime = Mon Sep 30 21:28:25 CST 2019pZxid = 0x100000007cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 13numChildren = 0 ​ 7）创建短暂节点 12[zk: localhost:2181(CONNECTED) 8] create -e /app-emphemeral 8888 Created /app-emphemeral ​ （1）在当前客户端是能查看到的 12[zk: localhost:2181(CONNECTED) 6] ls / [zookeeper, app1, app-emphemeral] ​ （2）退出当前客户端然后再重启客户端 12[zk: localhost:2181(CONNECTED) 7] quit[kaizhang@localhost bin]$ ./zkCli.sh ​ （3）再次查看根目录下短暂节点已经删除 12[zk: localhost:2181(CONNECTED) 0] ls /[zookeeper, app1] ​ 8）创建带序号的节点 ​ （1）先创建一个普通的根节点 app2 12[zk: localhost:2181(CONNECTED) 2] create /app2 &quot;app2&quot; Created /app2 ​ （2）创建带序号的节点 123456[zk: localhost:2181(CONNECTED) 4] create -s /app2/aa 888Created /app2/aa0000000000[zk: localhost:2181(CONNECTED) 5] create -s /app2/bb 888Created /app2/bb0000000001[zk: localhost:2181(CONNECTED) 6] create -s /app2/cc 888 Created /app2/cc0000000002 如果原节点下有 1 个节点，则再排序时从 1 开始，以此类推。 12[zk: localhost:2181(CONNECTED) 7] create -s /app1/aa 888 Created /app1/aa0000000001 9）修改节点数据值 123456789101112[zk: localhost:2181(CONNECTED) 8] set /app1 999 cZxid = 0x100000004ctime = Mon Sep 30 21:27:00 CST 2019mZxid = 0x10000001fmtime = Mon Sep 30 21:46:15 CST 2019pZxid = 0x100000007cversion = 1dataVersion = 3aclVersion = 0ephemeralOwner = 0x0dataLength = 3numChildren = 1 10）节点的值变化监听 ​ （1）在 101 主机上注册监听/app1 节点数据变化 1[zk: localhost:2181(CONNECTED) 26] get /app1 watch ​ （2）在 102 主机上修改/app1 节点的数据 1[zk: localhost:2181(CONNECTED) 5] set /app1 777 ​ （3）观察 101 主机收到数据变化的监听 123WATCHER::WatchedEvent state:SyncConnected type:NodeDataChanged path:/app1 11）节点的子节点变化监听（路径变化） （1）在 101 主机上注册监听/app1 节点的子节点变化 12[zk: localhost:2181(CONNECTED) 17] ls /app1 watch[server101] ​ （2）在 102 主机/app1 节点上创建子节点 12[zk: localhost:2181(CONNECTED) 15] create /app1/bb 666Created /app1/bb ​ （3）观察 101 主机收到子节点变化的监听 123WATCHER::WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/app1 12）删除节点 1[zk: localhost:2181(CONNECTED) 4] delete /app1/bb 13）递归删除节点 1[zk: localhost:2181(CONNECTED) 7] rmr /app2 14）查看节点状态 123456789101112[zk: localhost:2181(CONNECTED) 8] stat /app1 cZxid = 0x100000004ctime = Mon Sep 30 21:27:00 CST 2019mZxid = 0x100000021mtime = Mon Sep 30 21:51:53 CST 2019pZxid = 0x100000022cversion = 2dataVersion = 5aclVersion = 0ephemeralOwner = 0x0dataLength = 4numChildren = 2 1.3 API 应用参考： https://github.com/SparksFlyMe/zookeeperlearning 第2章 Zookeeper 内部原理2.1 选举机制1）半数机制（Paxos 协议）：集群中半数以上机器存活，集群可用。所以 zookeeper适合装在奇数台机器上。 2）Zookeeper 虽然在配置文件中并没有指定 master 和 slave。但是，zookeeper 工作时，是有一个节点为 leader，其他则为 follower，Leader 是通过内部的选举机制临时产生的 3）以一个简单的例子来说明整个选举的过程。 假设有五台服务器组成的 zookeeper 集群，它们的 id 从 1-5，同时它们都是最新启动的，也就是没有历史数据，在存放数据量这一点上，都是一样的。假设这些服务器依序启动，来看看会发生什么。 （1）服务器 1 启动，此时只有它一台服务器启动了，它发出去的报没有任何响应，所以它的选举状态一直是 LOOKING 状态。 （2）服务器 2 启动，它与最开始启动的服务器 1 进行通信，互相交换自己的选举结果，由于两者都没有历史数据，所以 id 值较大的服务器 2 胜出，但是由于没有达到超过半数以上的服务器都同意选举它(这个例子中的半数以上是 3)，所以服务器 1、2 还是继续保持LOOKING 状态。 （3）服务器 3 启动，根据前面的理论分析，服务器 3 成为服务器 1、2、3 中的老大，而与上面不同的是，此时有三台服务器选举了它，所以它成为了这次选举的 leader。 （4）服务器 4 启动，根据前面的分析，理论上服务器 4 应该是服务器 1、2、3、4 中最大的，但是由于前面已经有半数以上的服务器选举了服务器 3，所以它只能接收当小弟的命了。 （5）服务器 5 启动，同 4 一样当小弟。 2.2 节点类型1）Znode 有两种类型：短暂（ephemeral）：客户端和服务器端断开连接后，创建的节点自己删除持久（persistent）：客户端和服务器端断开连接后，创建的节点不删除 2）Znode 有四种形式的目录节点（默认是 persistent ）（1）持久化目录节点（PERSISTENT） 客户端与 zookeeper 断开连接后，该节点依旧存在（2）持久化顺序编号目录节点（PERSISTENT_SEQUENTIAL） 客户端与 zookeeper 断开连接后，该节点依旧存在，只是 Zookeeper 给该节点名称进行顺序编号 ​ （3）临时目录节点（EPHEMERAL）客户端与 zookeeper 断开连接后，该节点被删除（4）临时顺序编号目录节点（EPHEMERAL_SEQUENTIAL） 客户端与 zookeeper 断开连接后，该节点被删除，只是 Zookeeper 给该节点名称进行顺序编号 3）创建 znode 时设置顺序标识，znode 名称后会附加一个值，顺序号是一个单调递增的计数器，由父节点维护 4）在分布式系统中，顺序号可以被用于为所有的事件进行全局排序，这样客户端可以通过顺序号推断事件的顺序 2.3 stat 结构体1）czxid- 引起这个 znode 创建的 zxid，创建节点的事务的 zxid 每次修改 ZooKeeper 状态都会收到一个 zxid 形式的时间戳，也就是 ZooKeeper 事务 ID。事务 ID 是 ZooKeeper 中所有修改总的次序。每个修改都有唯一的 zxid，如果 zxid1 小于 zxid2，那么 zxid1 在 zxid2 之前发生。 2）ctime - znode 被创建的毫秒数(从 1970 年开始)3）mzxid - znode 最后更新的 zxid4）mtime - znode 最后修改的毫秒数(从 1970 年开始)5）pZxid-znode 最后更新的子节点 zxid6）cversion - znode 子节点变化号，znode 子节点修改次数7）dataversion - znode 数据变化号8）aclVersion - znode 访问控制列表的变化号9）ephemeralOwner- 如果是临时节点，这个是 znode 拥有者的 session id。如果不是临时节点则是 0。10）dataLength- znode 的数据长度11）numChildren - znode 子节点数量 2.4 监听器原理 1）监听原理详解：（1）首先要有一个 main()线程（2）在 main 线程中创建 Zookeeper 客户端，这时就会创建两个线程，一个负责网络连接通信（connet），一个负责监听（listener）。 （3）通过 connect 线程将注册的监听事件发送给 Zookeeper。（4）在 Zookeeper 的注册监听器列表中将注册的监听事件添加到列表中。（5）Zookeeper 监听到有数据或路径变化，就会将这个消息发送给 listener 线程。（6）listener 线程内部调用了 process（）方法。 2）常见的监听（1）监听节点数据的变化： 1get path [watch] （2）监听子节点增减的变化 1ls path [watch] 2.5 写数据流程 ZooKeeper 的写数据流程主要分为以下几步：1）比如 Client 向 ZooKeeper 的 Server1 上写数据，发送一个写请求。 2）如果 Server1 不是 Leader，那么 Server1 会把接受到的请求进一步转发给 Leader，因为每个 ZooKeeper 的 Server 里面有一个是 Leader。这个 Leader 会将写请求广播给各个Server，比如 Server1 和 Server2， 各个 Server 写成功后就会通知 Leader。 3）当 Leader 收到大多数 Server 数据写成功了，那么就说明数据写成功了。如果这里三个节点的话，只要有两个节点数据写成功了，那么就认为数据写成功了。写成功之后，Leader 会告诉 Server1 数据写成功了。 4）Server1 会进一步通知 Client 数据写成功了，这时就认为整个写操作成功。ZooKeeper 整个写数据流程就是这样的。]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper概述及单机搭建]]></title>
    <url>%2F2019%2F09%2F28%2FZookeeper%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8D%95%E6%9C%BA%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[第 1 章 Zookeeper 概述1.1 概述 Zookeeper 是一个开源的分布式的，为分布式应用提供协调服务的 Apache 项目。 Zookeeper 从设计模式角度来理解：是一个基于观察者模式设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生变化，Zookeeper 就将负责通知已经在 Zookeeper 上注册的那些观察者做出相应的反应，从而实现集群中类似 Master/Slave 管理模式 。 Zookeeper=文件系统+通知机制。 1.2 特点1）Zookeeper：一个领导者（leader），多个跟随者（follower）组成的集群。2）Leader 负责进行投票的发起和决议，更新系统状态3）Follower 用于接收客户请求并向客户端返回结果，在选举 Leader 过程中参与投票4）集群中只要有半数以上节点存活，Zookeeper 集群就能正常服务。5）全局数据一致：每个 server 保存一份相同的数据副本，client 无论连接到哪个 server，数据都是一致的。6）更新请求顺序进行，来自同一个 client 的更新请求按其发送顺序依次执行。7）数据更新原子性，一次数据更新要么成功，要么失败。8）实时性，在一定时间范围内，client 能读到最新数据。 1.3 数据结构 ZooKeeper 数据模型的结构与 Unix 文件系统很类似，整体上可以看作是一棵树，每个节点称做一个ZNode。 很显然 zookeeper 集群自身维护了一套数据结构。这个存储结构是一个树形结构，其上的每一个节点，我们称之为”znode”，每一个 znode 默认能够存储 1MB 的数据，每个 ZNode都可以通过其路径唯一标识 1.4 应用场景提供的服务包括：分布式消息同步和协调机制、服务器节点动态上下线、统一配置管理、负载均衡、集群管理等。 1.5 下载地址https://zookeeper.apache.org 第二章 Zookeeper 安装2.1 本地模式安装部署 （单机版）1）安装前准备： ​ （1）安装 jdk​ （2）通过 xshell等工具拷贝 zookeeper 到 linux 系统下​ （3）解压到指定目录 1[kaizhang@localhost software]$ tar -zvxf zookeeper-3.4.14.tar.gz 2）配置修改 ​ （1）将/opt/software/zookeeper-3.4.14/conf 这个路径下的 zoo_sample.cfg 复制为 zoo.cfg： 1[kaizhang@localhost conf]$ cp zoo_sample.cfg zoo.cfg ​ （2）进入 zoo.cfg 文件：vim zoo.cfg ​ 修改 dataDir 路径为​ dataDir=/opt/software/zookeeper-3.4.14/zkData ​ （3）在/opt/software/zookeeper-3.4.14/这个目录上创建 zkData 文件夹 1[kaizhang@localhost zookeeper-3.4.14]$ mkdir zkData 3）操作 zookeeper ​ （1）启动 zookeeper ： 1[kaizhang@localhost bin]$ ./zkServer.sh start ​ （2）查看进程是否启动 ： 123[kaizhang@localhost bin]$ jps8465 Jps7751 QuorumPeerMain ​ （3）查看状态： 1234[kaizhang@localhost bin]$ ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/software/zookeeper-3.4.14/bin/../conf/zoo.cfgMode: standalone ​ （4）启动客户端： 1[kaizhang@localhost bin]$ ./zkCli.sh ​ （5）退出客户端： 1[zk: localhost:2181(CONNECTED) 0] quit ​ （6）停止 zookeeper ： 1[kaizhang@localhost bin]$ ./zkServer.sh stop 2.2 配置参数解读解读zoo.cfg 文件中参数含义1）tickTime：通信心跳数。Zookeeper服务器心跳时间，单位毫秒 ​ Zookeeper使用的基本时间，服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每隔tickTime时间就会发送一个心跳，时间单位为毫秒。 ​ 它用于心跳机制，并且设置最小的session超时时间为两倍心跳时间。(session的最小超时时间是2*tickTime) 2）initLimit：LF初始通信时限 集群中的follower跟随者服务器(F)与leader领导者服务器(L)之间初始连接时能容忍的最多心跳数（tickTime的数量），用它来限定集群中的Zookeeper服务器连接到Leader的时限。 ​ 投票选举新leader的初始化时间​ Follower在启动过程中，会从Leader同步所有最新数据，然后确定自己能够对外服务的起始状态。 ​ Leader允许F在initLimit时间内完成这个工作。 3）syncLimit：LF 同步通信时限 集群中Leader与Follower之间的最大响应时间单位，假如响应超过syncLimit * tickTime，Leader认为Follwer死掉，从服务器列表中删除Follwer。 在运行过程中，Leader负责与ZK集群中所有机器进行通信，例如通过一些心跳检测机制，来检测机器的存活状态。 如果L发出心跳包在syncLimit之后，还没有从F那收到响应，那么就认为这个F已经不在线了。 4）dataDir：数据文件目录+数据持久化路径 保存内存数据库快照信息的位置，如果没有其他说明，更新的事务日志也保存到数据库。 5）clientPort：客户端连接端口 监听客户端连接的端口]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring自动装配]]></title>
    <url>%2F2019%2F07%2F21%2FSpring%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D%2F</url>
    <content type="text"><![CDATA[Spring的自动装配功能：自动装配：Spring利用依赖注入（DI），完成对IOC容器中各种组件的依赖关系赋值@Autowired的使用场景在构造器（CONSTRUCTOR），参数（PARAMETER），方法（METHOD），属性（FIELD），注释类型（ANNOTATION_TYPE）上，都能使用这个注解{@link Autowired}。且都是从容器中获取参数组件的值 标注在构造器上：默认加载在ioc容器中的组件，容器启动会调用无参构造器创建对象，再进行初始化赋值等操作。 构造器要用的组件，都是从容器中获取。如果组件只有一个有参构造器，这个有参构造器的@Autowired可以省略，参数位置的组件还是可以自动从容器中获取。 12345678910@Componentpublic class PersonService &#123; private Student student; @Autowired //可以省略 public PersonService(Student student)&#123; this.student = student; System.out.println("PersonService 有参构造器。。。"); &#125;&#125; 标注在参数上： 12345678@Componentpublic class PersonService &#123; private Student student; public PersonService(@Autowired Student student)&#123; this.student = student; &#125;&#125; 标注在方法上：Spring容器创建当前对象，就会调用方法，完成赋值；方法使用的参数，自定义类型的值从ioc容器中获取。常用的有：@Bean + 方法参数，参数从容器中获取 1234567891011121314@Componentpublic class PersonService &#123; private Student student; /** * * @param student 这里方法的参数（student）的值，从ioc容器中获取 * @return */ @Autowired public Student getStudent(Student student) &#123; return this.student = student; &#125;&#125; @Autowired的详细使用 默认优先按照类型去容器中找对应的组件。 1annotationConfigApplicationContext.getBean(BookDao.class); 如果找到多个相同类型的组件，再将属性的名称作为组件的id去容器中查找。 12345 /** * 这里bookDao为注入的属性名 */annotationConfigApplicationContext.getBean("bookDao") @Qualifier(“bookDao)：使用@Qualifier指定需要装配的组件的id，而不是使用属性名。 自动装配默认一定要将属性赋值好，如果没有就会报错。 @Autowired(required = true)，required默认为true，改为false后就不会报错 @Primary：让Spring进行自动装配的时候，默认使用首先的bean，也可以继续使用@Qualifier指定需要装配的bean的名字 @Autowired是Spring规范的注解，同时Spring还支持java规范的注解：@Resource（JSR250规范）和@Inject(JSR330规范) @Resource 可以和@Autowired一样实现自动装配功能；默认是按照组件名称进行装配的，不支持@Primary,也不支持@Autowired（require=false） @Inject 需要导入javax的包，和Autowired的功能一样。没有require=false的功能 注意事项这里说到的对各种组件的自动装配，前提是这些一定是Spring的组件（即需要添加@Configuration等注解）]]></content>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 注册组件的几种方式]]></title>
    <url>%2F2019%2F07%2F14%2FSpring-%E6%B3%A8%E5%86%8C%E7%BB%84%E4%BB%B6%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[在Spring中，给容器注册组件有多种方式，从之前的xml配置到后来的全注解配置，省去了复杂繁琐的xml配置，给开发人员带来的极大便利。给容器中注册组件的几种方式：1、包扫描 + 组件标注注解（@Controller、@Service、@Repository、@Component）2、@Bean（导入第三方包里面的组件，比如RestTemplate）3、@Import（快速给容器中导入一个组件） @Import（要导入到容器的组件）；容器中就会自动注册这个组件，id默认是全类名 实现ImportSelector类：返回需要导入的组件的全类名数组 实现ImportBeanDefinitionRegistrar：手动注册bean到容器中 4、使用Spring提供的FactoryBean(工厂Bean)]]></content>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis foreach循环 collection的三种方式]]></title>
    <url>%2F2019%2F07%2F13%2FMybatis-foreach%E5%BE%AA%E7%8E%AF-collection%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[自从有了Mybatis加强版Mybatis,再也不用写那么复杂麻烦的xml配置文件了！但是偶尔也有需求还得用xml，对于Mybatis的foreach也是经常用到的，但是每次都是从项目里粘贴复制、修修改改就用，对于其具体使用理解也是模模糊糊，导致有时用到的时候遇到各种问题，此文就针对Mybatis的foreach做个记录，以便更透彻的理解与使用。foreach标签主要用于构建in条件，它可以在sql中对集合进行迭代，通常可以将之用到批量删除、添加等操作中，示例如下： 1234567891011&lt;select id="getRequestLogList" parameterType="java.util.HashMap" resultType="RequestLog"&gt; SELECT * FROM request_log &lt;where&gt; &lt;if test="sessionIdList !=null and sessionIdList.size &gt; 0"&gt; and sessionId in ( &lt;foreach collection="sessionIdList" item="item" index="index" separator=","&gt; #&#123;item&#125; &lt;/foreach&gt; ) &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; 加入我们输入的参数为 Long sessionIdList[] = {1L, 2L, 4L}; 那么对应执行的sql就是 ： 1SELECT * FROM request_log where sessionId in (1, 2, 4); foreach元素的属性主要有 item，index，collection，open，separator，close。 ​ item：表示集合中每一个元素进行迭代时的别名， ​ index：指 定一个名字，用于表示在迭代过程中，每次迭代到的位置， ​ open：表示该语句以什么开始， ​ separator：表示在每次进行迭代之间以什么符号作为分隔 符， ​ close：表示以什么结束。 在使用foreach的时候最关键的也是最容易出错的就是collection属性，该属性是必须指定的，但是在不同情况 下，该属性的值是不一样的，主要有一下3种情况： ​ 如果传入的是单参数且参数类型是一个List的时候，collection属性值为list ​ 如果传入的是单参数且参数类型是一个array数组的时候，collection的属性值为array ​ 如果传入的参数是多个的时候，我们就需要把它们封装成一个Map了，当然单参数也可 1、collection属性为List方法调用 123public List&lt;Area&gt; findUserListByIdList(List&lt;Long&gt; idList) &#123; return getSqlSession().findUserListByIdList(idList); &#125; 对应的mapper： 123456789&lt;select id="findUserListByIdList" parameterType="java.util.ArrayList" resultType="User"&gt; select * from user &lt;where&gt; ID in ( &lt;foreach collection="list" item="guard" index="index" separator=","&gt; #&#123;guard&#125; &lt;/foreach&gt; ) &lt;/where&gt; &lt;/select&gt; 即单独传入list时，foreach中的collection必须是 list，不管变量的具体名称是什么。比如这里变量名为idList， collection却是List。 2、collection属性为array方法调用 123public List&lt;Area&gt; findUserListByIdList(int[] ids) &#123; return getSqlSession().findUserListByIdList(ids); &#125; 对应的mapper： 123456789&lt;select id="findUserListByIdList" parameterType="java.util.HashList" resultType="User"&gt; select * from user &lt;where&gt; ID in ( &lt;foreach collection="array" item="guard" index="index" separator=","&gt; #&#123;guard&#125; &lt;/foreach&gt; ) &lt;/where&gt; &lt;/select&gt; 单独传入数组时，foreach中的collection必须是 array，不管变量的具体名称是什么。比如这里变量名为ids，collection却是array。 3、collection属性为map方法调用： 12345public boolean exists(Map&lt;String, Object&gt; map)&#123; Object count = getSqlSession().exists(map); int totalCount = Integer.parseInt(count.toString()); return totalCount &gt; 0 ? true : false; &#125; 对应的mapper： 1234567891011121314151617&lt;select id="exists" parameterType="java.util.HashMap" resultType="java.lang.Integer"&gt; SELECT COUNT(*) FROM USER user &lt;where&gt; &lt;if test="code != null"&gt; and CODE = #&#123;code&#125; &lt;/if&gt; &lt;if test="id != null"&gt; and ID = #&#123;id&#125; &lt;/if&gt; &lt;if test="idList !=null "&gt; and ID in ( &lt;foreach collection="idList" item="guard" index="index" separator=","&gt; #&#123;guard&#125; &lt;/foreach&gt; ) &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; map中有list或array时，foreach中的collection必须是具体list或array的变量名。比如这里map含有一个名为idList的list，所以map中用idList(map的key)来取值，这点和单独传list或array时不太一样。 4、传入java对象调用方法 12345public boolean findUserListByDTO(UserDTO userDTO)&#123; Object count = getSqlSession().findUserListByDTO(userDTO); int totalCount = Integer.parseInt(count.toString()); return totalCount &gt; 0 ? true : false; &#125; 对应的mapper： 1234567891011121314151617select id="findUserListByDTO" parameterType="UserDTO" resultType="java.lang.Integer"&gt; SELECT COUNT(*) FROM USER user &lt;where&gt; &lt;if test="code != null"&gt; and CODE = #&#123;code&#125; &lt;/if&gt; &lt;if test="id != null"&gt; and ID = #&#123;id&#125; &lt;/if&gt; &lt;if test="idList !=null "&gt; and ID in ( &lt;foreach collection="idList" item="guard" index="index" separator=","&gt; #&#123;guard&#125; &lt;/foreach&gt; ) &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; JAVA对象中有list或array时，foreach中的collection必须是具体list或array的变量名。比如这里UserDTO含有一个名为idList的list，所以UserDTO中用idList取值，这点和单独传list或array时不太一样。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Mybatis foreach 使用错误记录]]></title>
    <url>%2F2019%2F07%2F13%2FMybatis-foreach-%E9%94%99%E8%AF%AF%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[使用Mybatis foreach遍历时，Error evaluating expression ‘sessionIdList’. Return value () was not iterable.问题的起因时这样的，同事用map方式传值，map里需要存入一个集合，但是在判断集合为空时放了空字符串，导致mybatis在遍历时无法把空字符串解析成集合。 传入map 1234567891011HashMap&lt;String, Object&gt; mapper = new HashMap&lt;String, Object&gt;(16);// 获取要遍历的sessionIdList集合List&lt;Long&gt; list = getSessionIdList();if (CollectionUtils.isEmpty(list)) &#123; mapper.put(&quot;sessionIdList&quot;, &quot;&quot;); //罪魁祸首在这里&#125; else &#123; mapper.put(&quot;sessionIdList&quot;, list);&#125;List&lt;RequestLog&gt; requestLogList = requestLogService.getRequestLogList(mapper); 对应mapper 1234567891011121314151617&lt;select id=&quot;getRequestLogList&quot; parameterType=&quot;java.util.HashMap&quot; resultType=&quot;RequestLog&quot;&gt; SELECT * FROM USER request_log &lt;where&gt; &lt;if test=&quot;code != null and code != &apos;&apos; &quot;&gt; and CODE = #&#123;code&#125; &lt;/if&gt; &lt;if test=&quot;id != null and id != &apos;&apos;&quot;&gt; and ID = #&#123;id&#125; &lt;/if&gt; &lt;if test=&quot;sessionIdList !=null and sessionIdList.size &gt; 0&quot;&gt; and sessionId in ( &lt;foreach collection=&quot;sessionIdList&quot; item=&quot;item&quot; index=&quot;index&quot; separator=&quot;,&quot;&gt; #&#123;item&#125; &lt;/foreach&gt; ) &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; 当调用getSessionIdList()方法获取到的集合为空时，传入的值是空字符串而非集合类型，从而在mapper.xml中解析时无法把字符串类型解析成集合类型，报出了Return value () was not iterable的问题。 另外还发现了另一个问题，在判断mapper.xm中集合是否为空时，不能与空字符串比较进行判断，而应该用size方法，否则会引起 invalid comparison: java.util.ArrayList and java.lang.String 把集合类型与字符串类型作比较，引起了“无效的比较”错误 反例 123456&lt;if test=&quot;sessionIdList !=null and sessionIdList != &apos;&apos;&quot;&gt; &lt;!--这里用!=&apos;&apos; 进行判断会报错，因为引起了集合与String类型的比较--&gt; and sessionId in ( &lt;foreach collection=&quot;sessionIdList&quot; item=&quot;item&quot; index=&quot;index&quot; separator=&quot;,&quot;&gt; #&#123;item&#125; &lt;/foreach&gt; ) &lt;/if&gt; 正例123456&lt;if test=&quot;sessionIdList !=null and sessionIdList.size &gt; 0 &apos;&apos;&quot;&gt; &lt;!--这里应该用sessionIdList.size &gt; 0 来判断集合是否为空--&gt; and sessionId in ( &lt;foreach collection=&quot;sessionIdList&quot; item=&quot;item&quot; index=&quot;index&quot; separator=&quot;,&quot;&gt; #&#123;item&#125; &lt;/foreach&gt; ) &lt;/if&gt; 总结当用mabatis foreach遍历时，遍历对象的类型一定要确认是否正确。一般有三种：list(集合)、array(数组)、map(map中传入集合)]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
      </tags>
  </entry>
</search>
