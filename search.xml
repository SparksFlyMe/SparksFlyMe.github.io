<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Kafka入门+实战]]></title>
    <url>%2F2019%2F11%2F30%2FKafka%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Kafka入门+实战第一章 Kafka概述]]></content>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper集群搭建及内部原理]]></title>
    <url>%2F2019%2F09%2F29%2FZookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E5%8F%8A%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[第1章 Zookeeper 实战1.1 分布式安装部署0）集群规划​ 在CentOS_1、CentOS_2 和CentOS_3 三个服务器上部署 Zookeeper。 1）解压安装​ （1）解压 zookeeper 安装包到/opt/software/目录下 1[kaizhang@localhost software]$ tar -zxvf zookeeper-3.4.14.tar.gz ​ （2）在/opt/software/zookeeper-3.4.14/这个目录下创建 zkData 1[kaizhang@localhost zookeeper-3.4.14]$ mkdir -p zkData ​ （3）复制/opt/software/zookeeper-3.4.14/conf 这个目录下的 zoo_sample.cfg 为 zoo.cfg 1[kaizhang@localhost conf]$ cp zoo_sample.cfg zoo.cfg 2）配置 zoo.cfg 文件​ （1）具体配置 dataDir=/opt/software/zookeeper-3.4.14/zkData 增加如下配置 #######################cluster##########################server.1=192.168.17.101:2888:3888server.2=192.168.17.102:2888:3888server.3=192.168.17.103:2888:3888 ​ （2）配置参数解读 Server.A=B:C:D。A 是一个数字，表示这个是第几号服务器；B 是这个服务器的 ip 地址；C 是这个服务器与集群中的 Leader 服务器交换信息的端口；D 是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。 集群模式下配置一个文件myid，这个文件在dataDir目录下，这个文件里面有一个数据就是 A 的值，Zookeeper 启动时读取此文件，拿到里面的数据与 zoo.cfg 里面的配置信息比较从而判断到底是哪个 server。 3）集群操作​ （1）在/opt/software/zookeeper-3.4.14/zkData 目录下创建一个 myid 的文件 1[kaizhang@localhost zkData]$ touch myid 添加 myid 文件，注意一定要在 linux 里面创建，在 notepad++里面很可能乱码 ​ （2）编辑 myid 文件 1[kaizhang@localhost zkData]$ vi myid 在文件中添加与 server 对应的编号：如 1 ​ （3） 在其他机器上进行相同的操作 ，并分别修改 myid 文件中内容为 2、3 ​ （4）在三台机器上分别启动 zookeeper 1[kaizhang@localhost bin]$ ./zkServer.sh start ​ （5）查看状态 1234567891011121314[kaizhang@localhost bin]$ ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/software/zookeeper-3.4.14/bin/../conf/zoo.cfgMode: leader[kaizhang@localhost bin]$ ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/software/zookeeper-3.4.14/bin/../conf/zoo.cfgMode: follower[kaizhang@localhost bin]$ ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/software/zookeeper-3.4.14/bin/../conf/zoo.cfgMode: follower 1.2 客户端命令行操作 命令基本语法 功能描述 help 显示所有操作命令 ls path [watch] 使用 ls 命令来查看当前znode中所包含的内容 ls2 path [watch] 查看当前节点数据并能看到更新次数等数据 create 普通创建 -s 含有序列 -e 临时（重启或者超时消失） get path [watch] 获得节点的值 set 设置节点的具体值 stat 查看节点状态 delete 删除节点 rmr 递归删除节点 ​ 1）启动客户端 1[kaizhang@localhost bin]$ ./zkCli.sh ​ 2）显示所有操作命令 1[zk: localhost:2181(CONNECTED) 0] help ​ 3）查看当前 znode 中所包含的内容 12[zk: localhost:2181(CONNECTED) 1] ls /[zookeeper] ​ 4）查看当前节点数据并能看到更新次数等数据 12345678910111213[zk: localhost:2181(CONNECTED) 2] ls2 /[zookeeper]cZxid = 0x0ctime = Thu Jan 01 08:00:00 CST 1970mZxid = 0x0mtime = Thu Jan 01 08:00:00 CST 1970pZxid = 0x0cversion = -1dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 0numChildren = 1 ​ 5）创建普通节点 12345[zk: localhost:2181(CONNECTED) 3] create /app1 &quot;hello app1&quot; Created /app1[zk: localhost:2181(CONNECTED) 4] create /app1/server101 &quot;192.168.1.101&quot;Created /app1/server101 ​ 6）获得节点的值 123456789101112131415161718192021222324252627[zk: localhost:2181(CONNECTED) 5] get /app1hello app1cZxid = 0x100000004ctime = Mon Sep 30 21:27:00 CST 2019mZxid = 0x100000004mtime = Mon Sep 30 21:27:00 CST 2019pZxid = 0x100000007cversion = 1dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 10numChildren = 1[zk: localhost:2181(CONNECTED) 6] get /app1/server101192.168.1.101cZxid = 0x100000007ctime = Mon Sep 30 21:28:25 CST 2019mZxid = 0x100000007mtime = Mon Sep 30 21:28:25 CST 2019pZxid = 0x100000007cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 13numChildren = 0 ​ 7）创建短暂节点 12[zk: localhost:2181(CONNECTED) 8] create -e /app-emphemeral 8888 Created /app-emphemeral ​ （1）在当前客户端是能查看到的 12[zk: localhost:2181(CONNECTED) 6] ls / [zookeeper, app1, app-emphemeral] ​ （2）退出当前客户端然后再重启客户端 12[zk: localhost:2181(CONNECTED) 7] quit[kaizhang@localhost bin]$ ./zkCli.sh ​ （3）再次查看根目录下短暂节点已经删除 12[zk: localhost:2181(CONNECTED) 0] ls /[zookeeper, app1] ​ 8）创建带序号的节点 ​ （1）先创建一个普通的根节点 app2 12[zk: localhost:2181(CONNECTED) 2] create /app2 &quot;app2&quot; Created /app2 ​ （2）创建带序号的节点 123456[zk: localhost:2181(CONNECTED) 4] create -s /app2/aa 888Created /app2/aa0000000000[zk: localhost:2181(CONNECTED) 5] create -s /app2/bb 888Created /app2/bb0000000001[zk: localhost:2181(CONNECTED) 6] create -s /app2/cc 888 Created /app2/cc0000000002 如果原节点下有 1 个节点，则再排序时从 1 开始，以此类推。 12[zk: localhost:2181(CONNECTED) 7] create -s /app1/aa 888 Created /app1/aa0000000001 9）修改节点数据值 123456789101112[zk: localhost:2181(CONNECTED) 8] set /app1 999 cZxid = 0x100000004ctime = Mon Sep 30 21:27:00 CST 2019mZxid = 0x10000001fmtime = Mon Sep 30 21:46:15 CST 2019pZxid = 0x100000007cversion = 1dataVersion = 3aclVersion = 0ephemeralOwner = 0x0dataLength = 3numChildren = 1 10）节点的值变化监听 ​ （1）在 101 主机上注册监听/app1 节点数据变化 1[zk: localhost:2181(CONNECTED) 26] get /app1 watch ​ （2）在 102 主机上修改/app1 节点的数据 1[zk: localhost:2181(CONNECTED) 5] set /app1 777 ​ （3）观察 101 主机收到数据变化的监听 123WATCHER::WatchedEvent state:SyncConnected type:NodeDataChanged path:/app1 11）节点的子节点变化监听（路径变化） （1）在 101 主机上注册监听/app1 节点的子节点变化 12[zk: localhost:2181(CONNECTED) 17] ls /app1 watch[server101] ​ （2）在 102 主机/app1 节点上创建子节点 12[zk: localhost:2181(CONNECTED) 15] create /app1/bb 666Created /app1/bb ​ （3）观察 101 主机收到子节点变化的监听 123WATCHER::WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/app1 12）删除节点 1[zk: localhost:2181(CONNECTED) 4] delete /app1/bb 13）递归删除节点 1[zk: localhost:2181(CONNECTED) 7] rmr /app2 14）查看节点状态 123456789101112[zk: localhost:2181(CONNECTED) 8] stat /app1 cZxid = 0x100000004ctime = Mon Sep 30 21:27:00 CST 2019mZxid = 0x100000021mtime = Mon Sep 30 21:51:53 CST 2019pZxid = 0x100000022cversion = 2dataVersion = 5aclVersion = 0ephemeralOwner = 0x0dataLength = 4numChildren = 2 1.3 API 应用参考： https://github.com/SparksFlyMe/zookeeperlearning 第2章 Zookeeper 内部原理2.1 选举机制1）半数机制（Paxos 协议）：集群中半数以上机器存活，集群可用。所以 zookeeper适合装在奇数台机器上。 2）Zookeeper 虽然在配置文件中并没有指定 master 和 slave。但是，zookeeper 工作时，是有一个节点为 leader，其他则为 follower，Leader 是通过内部的选举机制临时产生的 3）以一个简单的例子来说明整个选举的过程。 假设有五台服务器组成的 zookeeper 集群，它们的 id 从 1-5，同时它们都是最新启动的，也就是没有历史数据，在存放数据量这一点上，都是一样的。假设这些服务器依序启动，来看看会发生什么。 （1）服务器 1 启动，此时只有它一台服务器启动了，它发出去的报没有任何响应，所以它的选举状态一直是 LOOKING 状态。 （2）服务器 2 启动，它与最开始启动的服务器 1 进行通信，互相交换自己的选举结果，由于两者都没有历史数据，所以 id 值较大的服务器 2 胜出，但是由于没有达到超过半数以上的服务器都同意选举它(这个例子中的半数以上是 3)，所以服务器 1、2 还是继续保持LOOKING 状态。 （3）服务器 3 启动，根据前面的理论分析，服务器 3 成为服务器 1、2、3 中的老大，而与上面不同的是，此时有三台服务器选举了它，所以它成为了这次选举的 leader。 （4）服务器 4 启动，根据前面的分析，理论上服务器 4 应该是服务器 1、2、3、4 中最大的，但是由于前面已经有半数以上的服务器选举了服务器 3，所以它只能接收当小弟的命了。 （5）服务器 5 启动，同 4 一样当小弟。 2.2 节点类型1）Znode 有两种类型：短暂（ephemeral）：客户端和服务器端断开连接后，创建的节点自己删除持久（persistent）：客户端和服务器端断开连接后，创建的节点不删除 2）Znode 有四种形式的目录节点（默认是 persistent ）（1）持久化目录节点（PERSISTENT） 客户端与 zookeeper 断开连接后，该节点依旧存在（2）持久化顺序编号目录节点（PERSISTENT_SEQUENTIAL） 客户端与 zookeeper 断开连接后，该节点依旧存在，只是 Zookeeper 给该节点名称进行顺序编号 ​ （3）临时目录节点（EPHEMERAL）客户端与 zookeeper 断开连接后，该节点被删除（4）临时顺序编号目录节点（EPHEMERAL_SEQUENTIAL） 客户端与 zookeeper 断开连接后，该节点被删除，只是 Zookeeper 给该节点名称进行顺序编号 3）创建 znode 时设置顺序标识，znode 名称后会附加一个值，顺序号是一个单调递增的计数器，由父节点维护 4）在分布式系统中，顺序号可以被用于为所有的事件进行全局排序，这样客户端可以通过顺序号推断事件的顺序 2.3 stat 结构体1）czxid- 引起这个 znode 创建的 zxid，创建节点的事务的 zxid 每次修改 ZooKeeper 状态都会收到一个 zxid 形式的时间戳，也就是 ZooKeeper 事务 ID。事务 ID 是 ZooKeeper 中所有修改总的次序。每个修改都有唯一的 zxid，如果 zxid1 小于 zxid2，那么 zxid1 在 zxid2 之前发生。 2）ctime - znode 被创建的毫秒数(从 1970 年开始)3）mzxid - znode 最后更新的 zxid4）mtime - znode 最后修改的毫秒数(从 1970 年开始)5）pZxid-znode 最后更新的子节点 zxid6）cversion - znode 子节点变化号，znode 子节点修改次数7）dataversion - znode 数据变化号8）aclVersion - znode 访问控制列表的变化号9）ephemeralOwner- 如果是临时节点，这个是 znode 拥有者的 session id。如果不是临时节点则是 0。10）dataLength- znode 的数据长度11）numChildren - znode 子节点数量 2.4 监听器原理 1）监听原理详解：（1）首先要有一个 main()线程（2）在 main 线程中创建 Zookeeper 客户端，这时就会创建两个线程，一个负责网络连接通信（connet），一个负责监听（listener）。 （3）通过 connect 线程将注册的监听事件发送给 Zookeeper。（4）在 Zookeeper 的注册监听器列表中将注册的监听事件添加到列表中。（5）Zookeeper 监听到有数据或路径变化，就会将这个消息发送给 listener 线程。（6）listener 线程内部调用了 process（）方法。 2）常见的监听（1）监听节点数据的变化： 1get path [watch] （2）监听子节点增减的变化 1ls path [watch] 2.5 写数据流程 ZooKeeper 的写数据流程主要分为以下几步：1）比如 Client 向 ZooKeeper 的 Server1 上写数据，发送一个写请求。 2）如果 Server1 不是 Leader，那么 Server1 会把接受到的请求进一步转发给 Leader，因为每个 ZooKeeper 的 Server 里面有一个是 Leader。这个 Leader 会将写请求广播给各个Server，比如 Server1 和 Server2， 各个 Server 写成功后就会通知 Leader。 3）当 Leader 收到大多数 Server 数据写成功了，那么就说明数据写成功了。如果这里三个节点的话，只要有两个节点数据写成功了，那么就认为数据写成功了。写成功之后，Leader 会告诉 Server1 数据写成功了。 4）Server1 会进一步通知 Client 数据写成功了，这时就认为整个写操作成功。ZooKeeper 整个写数据流程就是这样的。]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper概述及单机搭建]]></title>
    <url>%2F2019%2F09%2F28%2FZookeeper%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8D%95%E6%9C%BA%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[第 1 章 Zookeeper 概述1.1 概述 Zookeeper 是一个开源的分布式的，为分布式应用提供协调服务的 Apache 项目。 Zookeeper 从设计模式角度来理解：是一个基于观察者模式设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生变化，Zookeeper 就将负责通知已经在 Zookeeper 上注册的那些观察者做出相应的反应，从而实现集群中类似 Master/Slave 管理模式 。 Zookeeper=文件系统+通知机制。 1.2 特点1）Zookeeper：一个领导者（leader），多个跟随者（follower）组成的集群。2）Leader 负责进行投票的发起和决议，更新系统状态3）Follower 用于接收客户请求并向客户端返回结果，在选举 Leader 过程中参与投票4）集群中只要有半数以上节点存活，Zookeeper 集群就能正常服务。5）全局数据一致：每个 server 保存一份相同的数据副本，client 无论连接到哪个 server，数据都是一致的。6）更新请求顺序进行，来自同一个 client 的更新请求按其发送顺序依次执行。7）数据更新原子性，一次数据更新要么成功，要么失败。8）实时性，在一定时间范围内，client 能读到最新数据。 1.3 数据结构 ZooKeeper 数据模型的结构与 Unix 文件系统很类似，整体上可以看作是一棵树，每个节点称做一个 ZNode。 很显然 zookeeper 集群自身维护了一套数据结构。这个存储结构是一个树形结构，其上的每一个节点，我们称之为”znode”，每一个 znode 默认能够存储 1MB 的数据，每个 ZNode都可以通过其路径唯一标识 1.4 应用场景提供的服务包括：分布式消息同步和协调机制、服务器节点动态上下线、统一配置管理、负载均衡、集群管理等。 1.5 下载地址https://zookeeper.apache.org 第二章 Zookeeper 安装2.1 本地模式安装部署 （单机版）1）安装前准备： ​ （1）安装 jdk​ （2）通过 xshell等工具拷贝 zookeeper 到 linux 系统下​ （3）解压到指定目录 1[kaizhang@localhost software]$ tar -zvxf zookeeper-3.4.14.tar.gz 2）配置修改 ​ （1）将/opt/software/zookeeper-3.4.14/conf 这个路径下的 zoo_sample.cfg 复制为 zoo.cfg： 1[kaizhang@localhost conf]$ cp zoo_sample.cfg zoo.cfg ​ （2）进入 zoo.cfg 文件：vim zoo.cfg ​ 修改 dataDir 路径为​ dataDir=/opt/software/zookeeper-3.4.14/zkData ​ （3）在/opt/software/zookeeper-3.4.14/这个目录上创建 zkData 文件夹 1[kaizhang@localhost zookeeper-3.4.14]$ mkdir zkData 3）操作 zookeeper ​ （1）启动 zookeeper ： 1[kaizhang@localhost bin]$ ./zkServer.sh start ​ （2）查看进程是否启动 ： 123[kaizhang@localhost bin]$ jps8465 Jps7751 QuorumPeerMain ​ （3）查看状态： 1234[kaizhang@localhost bin]$ ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/software/zookeeper-3.4.14/bin/../conf/zoo.cfgMode: standalone ​ （4）启动客户端： 1[kaizhang@localhost bin]$ ./zkCli.sh ​ （5）退出客户端： 1[zk: localhost:2181(CONNECTED) 0] quit ​ （6）停止 zookeeper ： 1[kaizhang@localhost bin]$ ./zkServer.sh stop 2.2 配置参数解读解读zoo.cfg 文件中参数含义1）tickTime：通信心跳数，Zookeeper服务器心跳时间，单位毫秒Zookeeper使用的基本时间，服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每隔tickTime时间就会发送一个心跳，时间单位为毫秒。它用于心跳机制，并且设置最小的session超时时间为两倍心跳时间。(session的最小超时时间是2*tickTime) 2）initLimit：LF初始通信时限集群中的follower跟随者服务器(F)与leader领导者服务器(L)之间初始连接时能容忍的最多心跳数（tickTime的数量），用它来限定集群中的Zookeeper服务器连接到Leader的时限。 投票选举新leader的初始化时间Follower在启动过程中，会从Leader同步所有最新数据，然后确定自己能够对外服务的起始状态。Leader允许F在initLimit时间内完成这个工作。 3）syncLimit：LF 同步通信时限集群中Leader与Follower之间的最大响应时间单位，假如响应超过syncLimit * tickTime， Leader认为Follwer死掉，从服务器列表中删除Follwer。在运行过程中，Leader负责与ZK集群中所有机器进行通信，例如通过一些心跳检测机制，来检测机器的存活状态。如果L发出心跳包在syncLimit之后，还没有从F那收到响应，那么就认为这个F已经不在线了。 4）dataDir：数据文件目录+数据持久化路径保存内存数据库快照信息的位置，如果没有其他说明，更新的事务日志也保存到数据库。 5）clientPort：客户端连接端口监听客户端连接的端口]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring自动装配]]></title>
    <url>%2F2019%2F07%2F21%2FSpring%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D%2F</url>
    <content type="text"><![CDATA[Spring的自动装配功能：自动装配：Spring利用依赖注入（DI），完成对IOC容器中各种组件的依赖关系赋值@Autowired的使用场景在构造器（CONSTRUCTOR），参数（PARAMETER），方法（METHOD），属性（FIELD），注释类型（ANNOTATION_TYPE）上，都能使用这个注解{@link Autowired}。且都是从容器中获取参数组件的值 标注在构造器上：默认加载在ioc容器中的组件，容器启动会调用无参构造器创建对象，再进行初始化赋值等操作。 构造器要用的组件，都是从容器中获取。如果组件只有一个有参构造器，这个有参构造器的@Autowired可以省略，参数位置的组件还是可以自动从容器中获取。 12345678910@Componentpublic class PersonService &#123; private Student student; @Autowired //可以省略 public PersonService(Student student)&#123; this.student = student; System.out.println("PersonService 有参构造器。。。"); &#125;&#125; 标注在参数上： 12345678@Componentpublic class PersonService &#123; private Student student; public PersonService(@Autowired Student student)&#123; this.student = student; &#125;&#125; 标注在方法上：Spring容器创建当前对象，就会调用方法，完成赋值；方法使用的参数，自定义类型的值从ioc容器中获取。常用的有：@Bean + 方法参数，参数从容器中获取 1234567891011121314@Componentpublic class PersonService &#123; private Student student; /** * * @param student 这里方法的参数（student）的值，从ioc容器中获取 * @return */ @Autowired public Student getStudent(Student student) &#123; return this.student = student; &#125;&#125; @Autowired的详细使用 默认优先按照类型去容器中找对应的组件。 1annotationConfigApplicationContext.getBean(BookDao.class); 如果找到多个相同类型的组件，再将属性的名称作为组件的id去容器中查找。 12345 /** * 这里bookDao为注入的属性名 */annotationConfigApplicationContext.getBean("bookDao") @Qualifier(“bookDao)：使用@Qualifier指定需要装配的组件的id，而不是使用属性名。 自动装配默认一定要将属性赋值好，如果没有就会报错。 @Autowired(required = true)，required默认为true，改为false后就不会报错 @Primary：让Spring进行自动装配的时候，默认使用首先的bean，也可以继续使用@Qualifier指定需要装配的bean的名字 @Autowired是Spring规范的注解，同时Spring还支持java规范的注解：@Resource（JSR250规范）和@Inject(JSR330规范) @Resource 可以和@Autowired一样实现自动装配功能；默认是按照组件名称进行装配的，不支持@Primary,也不支持@Autowired（require=false） @Inject 需要导入javax的包，和Autowired的功能一样。没有require=false的功能 注意事项这里说到的对各种组件的自动装配，前提是这些一定是Spring的组件（即需要添加@Configuration等注解）]]></content>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 注册组件的几种方式]]></title>
    <url>%2F2019%2F07%2F14%2FSpring-%E6%B3%A8%E5%86%8C%E7%BB%84%E4%BB%B6%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[在Spring中，给容器注册组件有多种方式，从之前的xml配置到后来的全注解配置，省去了复杂繁琐的xml配置，给开发人员带来的极大便利。给容器中注册组件的几种方式：1、包扫描 + 组件标注注解（@Controller、@Service、@Repository、@Component）2、@Bean（导入第三方包里面的组件，比如RestTemplate）3、@Import（快速给容器中导入一个组件） @Import（要导入到容器的组件）；容器中就会自动注册这个组件，id默认是全类名 实现ImportSelector类：返回需要导入的组件的全类名数组 实现ImportBeanDefinitionRegistrar：手动注册bean到容器中 4、使用Spring提供的FactoryBean(工厂Bean)]]></content>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis foreach循环 collection的三种方式]]></title>
    <url>%2F2019%2F07%2F13%2FMybatis-foreach%E5%BE%AA%E7%8E%AF-collection%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[自从有了Mybatis加强版Mybatis,再也不用写那么复杂麻烦的xml配置文件了！但是偶尔也有需求还得用xml，对于Mybatis的foreach也是经常用到的，但是每次都是从项目里粘贴复制、修修改改就用，对于其具体使用理解也是模模糊糊，导致有时用到的时候遇到各种问题，此文就针对Mybatis的foreach做个记录，以便更透彻的理解与使用。foreach标签主要用于构建in条件，它可以在sql中对集合进行迭代，通常可以将之用到批量删除、添加等操作中，示例如下： 1234567891011&lt;select id="getRequestLogList" parameterType="java.util.HashMap" resultType="RequestLog"&gt; SELECT * FROM request_log &lt;where&gt; &lt;if test="sessionIdList !=null and sessionIdList.size &gt; 0"&gt; and sessionId in ( &lt;foreach collection="sessionIdList" item="item" index="index" separator=","&gt; #&#123;item&#125; &lt;/foreach&gt; ) &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; 加入我们输入的参数为 Long sessionIdList[] = {1L, 2L, 4L}; 那么对应执行的sql就是 ： 1SELECT * FROM request_log where sessionId in (1, 2, 4); foreach元素的属性主要有 item，index，collection，open，separator，close。 ​ item：表示集合中每一个元素进行迭代时的别名， ​ index：指 定一个名字，用于表示在迭代过程中，每次迭代到的位置， ​ open：表示该语句以什么开始， ​ separator：表示在每次进行迭代之间以什么符号作为分隔 符， ​ close：表示以什么结束。 在使用foreach的时候最关键的也是最容易出错的就是collection属性，该属性是必须指定的，但是在不同情况 下，该属性的值是不一样的，主要有一下3种情况： ​ 如果传入的是单参数且参数类型是一个List的时候，collection属性值为list ​ 如果传入的是单参数且参数类型是一个array数组的时候，collection的属性值为array ​ 如果传入的参数是多个的时候，我们就需要把它们封装成一个Map了，当然单参数也可 1、collection属性为List方法调用 123public List&lt;Area&gt; findUserListByIdList(List&lt;Long&gt; idList) &#123; return getSqlSession().findUserListByIdList(idList); &#125; 对应的mapper： 123456789&lt;select id="findUserListByIdList" parameterType="java.util.ArrayList" resultType="User"&gt; select * from user &lt;where&gt; ID in ( &lt;foreach collection="list" item="guard" index="index" separator=","&gt; #&#123;guard&#125; &lt;/foreach&gt; ) &lt;/where&gt; &lt;/select&gt; 即单独传入list时，foreach中的collection必须是 list，不管变量的具体名称是什么。比如这里变量名为idList， collection却是List。 2、collection属性为array方法调用 123public List&lt;Area&gt; findUserListByIdList(int[] ids) &#123; return getSqlSession().findUserListByIdList(ids); &#125; 对应的mapper： 123456789&lt;select id="findUserListByIdList" parameterType="java.util.HashList" resultType="User"&gt; select * from user &lt;where&gt; ID in ( &lt;foreach collection="array" item="guard" index="index" separator=","&gt; #&#123;guard&#125; &lt;/foreach&gt; ) &lt;/where&gt; &lt;/select&gt; 单独传入数组时，foreach中的collection必须是 array，不管变量的具体名称是什么。比如这里变量名为ids，collection却是array。 3、collection属性为map方法调用： 12345public boolean exists(Map&lt;String, Object&gt; map)&#123; Object count = getSqlSession().exists(map); int totalCount = Integer.parseInt(count.toString()); return totalCount &gt; 0 ? true : false; &#125; 对应的mapper： 1234567891011121314151617&lt;select id="exists" parameterType="java.util.HashMap" resultType="java.lang.Integer"&gt; SELECT COUNT(*) FROM USER user &lt;where&gt; &lt;if test="code != null"&gt; and CODE = #&#123;code&#125; &lt;/if&gt; &lt;if test="id != null"&gt; and ID = #&#123;id&#125; &lt;/if&gt; &lt;if test="idList !=null "&gt; and ID in ( &lt;foreach collection="idList" item="guard" index="index" separator=","&gt; #&#123;guard&#125; &lt;/foreach&gt; ) &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; map中有list或array时，foreach中的collection必须是具体list或array的变量名。比如这里map含有一个名为idList的list，所以map中用idList(map的key)来取值，这点和单独传list或array时不太一样。 4、传入java对象调用方法 12345public boolean findUserListByDTO(UserDTO userDTO)&#123; Object count = getSqlSession().findUserListByDTO(userDTO); int totalCount = Integer.parseInt(count.toString()); return totalCount &gt; 0 ? true : false; &#125; 对应的mapper： 1234567891011121314151617select id="findUserListByDTO" parameterType="UserDTO" resultType="java.lang.Integer"&gt; SELECT COUNT(*) FROM USER user &lt;where&gt; &lt;if test="code != null"&gt; and CODE = #&#123;code&#125; &lt;/if&gt; &lt;if test="id != null"&gt; and ID = #&#123;id&#125; &lt;/if&gt; &lt;if test="idList !=null "&gt; and ID in ( &lt;foreach collection="idList" item="guard" index="index" separator=","&gt; #&#123;guard&#125; &lt;/foreach&gt; ) &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; JAVA对象中有list或array时，foreach中的collection必须是具体list或array的变量名。比如这里UserDTO含有一个名为idList的list，所以UserDTO中用idList取值，这点和单独传list或array时不太一样。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Mybatis foreach 使用错误记录]]></title>
    <url>%2F2019%2F07%2F13%2FMybatis-foreach-%E9%94%99%E8%AF%AF%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[使用Mybatis foreach遍历时，Error evaluating expression ‘sessionIdList’. Return value () was not iterable.问题的起因时这样的，同事用map方式传值，map里需要存入一个集合，但是在判断集合为空时放了空字符串，导致mybatis在遍历时无法把空字符串解析成集合。 传入map 1234567891011HashMap&lt;String, Object&gt; mapper = new HashMap&lt;String, Object&gt;(16);// 获取要遍历的sessionIdList集合List&lt;Long&gt; list = getSessionIdList();if (CollectionUtils.isEmpty(list)) &#123; mapper.put(&quot;sessionIdList&quot;, &quot;&quot;); //罪魁祸首在这里&#125; else &#123; mapper.put(&quot;sessionIdList&quot;, list);&#125;List&lt;RequestLog&gt; requestLogList = requestLogService.getRequestLogList(mapper); 对应mapper 1234567891011121314151617&lt;select id=&quot;getRequestLogList&quot; parameterType=&quot;java.util.HashMap&quot; resultType=&quot;RequestLog&quot;&gt; SELECT * FROM USER request_log &lt;where&gt; &lt;if test=&quot;code != null and code != &apos;&apos; &quot;&gt; and CODE = #&#123;code&#125; &lt;/if&gt; &lt;if test=&quot;id != null and id != &apos;&apos;&quot;&gt; and ID = #&#123;id&#125; &lt;/if&gt; &lt;if test=&quot;sessionIdList !=null and sessionIdList.size &gt; 0&quot;&gt; and sessionId in ( &lt;foreach collection=&quot;sessionIdList&quot; item=&quot;item&quot; index=&quot;index&quot; separator=&quot;,&quot;&gt; #&#123;item&#125; &lt;/foreach&gt; ) &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; 当调用getSessionIdList()方法获取到的集合为空时，传入的值是空字符串而非集合类型，从而在mapper.xml中解析时无法把字符串类型解析成集合类型，报出了Return value () was not iterable的问题。 另外还发现了另一个问题，在判断mapper.xm中集合是否为空时，不能与空字符串比较进行判断，而应该用size方法，否则会引起 invalid comparison: java.util.ArrayList and java.lang.String 把集合类型与字符串类型作比较，引起了“无效的比较”错误 反例 123456&lt;if test=&quot;sessionIdList !=null and sessionIdList != &apos;&apos;&quot;&gt; &lt;!--这里用!=&apos;&apos; 进行判断会报错，因为引起了集合与String类型的比较--&gt; and sessionId in ( &lt;foreach collection=&quot;sessionIdList&quot; item=&quot;item&quot; index=&quot;index&quot; separator=&quot;,&quot;&gt; #&#123;item&#125; &lt;/foreach&gt; ) &lt;/if&gt; 正例123456&lt;if test=&quot;sessionIdList !=null and sessionIdList.size &gt; 0 &apos;&apos;&quot;&gt; &lt;!--这里应该用sessionIdList.size &gt; 0 来判断集合是否为空--&gt; and sessionId in ( &lt;foreach collection=&quot;sessionIdList&quot; item=&quot;item&quot; index=&quot;index&quot; separator=&quot;,&quot;&gt; #&#123;item&#125; &lt;/foreach&gt; ) &lt;/if&gt; 总结当用mabatis foreach遍历时，遍历对象的类型一定要确认是否正确。一般有三种：list(集合)、array(数组)、map(map中传入集合)]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
      </tags>
  </entry>
</search>
